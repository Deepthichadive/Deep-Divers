Title

"Authorship Attribution for Neural Text Generation"

-----------------------------------------------------------

About

In this project, for Milestone 2 we implemented Multi-Class
Classification models and ran on the problems given in the project description which is task 1(Same Method or Not), task 2(Human vs.
Machine) and task 3(Authorship Attribution) and also we have implemented
the above 3 tasks using the Nueral methods such as LSTM, LSTM-LSTM,
CNN-LSTM, Stacked-CNN, RNN-GRU and Parallel-CNN.

For milestone 3, we implemented BERT on all the given 3 tasks from the
project description and also we implemented POS Tagging on Nueral
Network methods such as LSTM-LSTM, Stacked-CNN, CNN-LSTM Parallel-CNN
and XGBoos especially on task 3.

-----------------------------------------------------------

Required Installations

Jupyter Notebook 
Anaconda Prompt

-----------------------------------------------------------

Usage

Milestone2: Run the Milestone2.ipynb file. The program uses the data under the data folder, named 'all_11_models_including_human' to train data and to test model we use the 'balanced_p1' for Task1,'balanced_p2' for Task2 and 'task3_data' for Task3.

Milestone3: Run the Milestone3_Improvements.ipynb. The BERT program uses the data under the data folder, named 'all_11_models_including_human' to train data and to test model we use the 'balanced_p1' for Task1, 'balanced_p2' for Task2 and 'task3_data' for Task3. The POS Tagging
on Nueral methods we use 'all_11_methods_without_cleaning_text' to train the data and we save the models under .h5 files and to test the
data we use the 'task_3_data_without_cleaning' data.

-----------------------------------------------------------

Authors

Ankit Nigam Gajjala - ankitnig@buffalo.edu 
Deepthi Chadive - deepthic@buffalo.edu 
Sreshta Aenugu - sreshtaa@buffalo.edu
Varshitha Bathula - vbathula@buffalo.edu 



-----------------------------------------------------------
